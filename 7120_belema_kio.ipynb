{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ag4GtQuI-LbLxNkufm-RiWoCj89KqgY4",
      "authorship_tag": "ABX9TyN+E+2z7Q5VB2OaXMbaBtJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrsbelema/belema/blob/main/7120_belema_kio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary packages"
      ],
      "metadata": {
        "id": "XD4Jcg6QyGEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_WwevGgx9j3",
        "outputId": "66d7cd39-9e80-46ab-cb63-cdd7c3a9ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, emoji, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 emoji-2.12.1 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk contractions emoji textblob\n",
        "!pip install scikit-learn\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "cMmLTvjWybl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "import emoji\n",
        "import contractions\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv"
      ],
      "metadata": {
        "id": "1dF015ppyZKf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download necessary NLTK resources"
      ],
      "metadata": {
        "id": "tXP6yeyS0sdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylmj97CYFvge",
        "outputId": "3ee855ae-e8f1-4272-c95f-d474e062b1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data from file"
      ],
      "metadata": {
        "id": "IfJB274eyx3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5sIxhcn0PIS_"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/4A-English/SemEval2017-task4-dev.subtask-A.english.INPUT.txt'\n",
        "data = pd.read_csv(file_path, sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract texts and labels"
      ],
      "metadata": {
        "id": "wCoWtOoAzCw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data[data.columns[2]].to_numpy()\n",
        "labels = data[data.columns[1]].to_numpy()"
      ],
      "metadata": {
        "id": "XkHkKZOLzARz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function for text cleaning"
      ],
      "metadata": {
        "id": "EUOKE_bwzRm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Text Cleaning\n",
        "def clean_text(text):\n",
        "    # Remove Twitter handles (usernames)\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Clean and preprocess texts\n",
        "cleaned_texts = [clean_text(text) for text in texts]"
      ],
      "metadata": {
        "id": "dDiQyTcEy9_1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization, stopword removal, lemmatization"
      ],
      "metadata": {
        "id": "1P4xHnvKzajz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenization (splitting into words)\n",
        "tokenized_texts = [nltk.word_tokenize(text) for text in cleaned_texts]\n",
        "\n",
        "# Step 3: Stopword Removal\n",
        "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
        "filtered_texts = [[word for word in tokens if word not in stop_words] for tokens in tokenized_texts]\n",
        "\n",
        "# Step 4: Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_texts = [[lemmatizer.lemmatize(word) for word in tokens] for tokens in filtered_texts]\n",
        "\n",
        "# Step 5: Joining tokens back into sentences\n",
        "preprocessed_texts = [' '.join(tokens) for tokens in lemmatized_texts]"
      ],
      "metadata": {
        "id": "7xkaUJAZzXfi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsxI-1rtPPru"
      },
      "source": [
        "Feature Extraction (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VNHHhMJpPSnf"
      },
      "outputs": [],
      "source": [
        "# Define TF-IDF vectorizer with parameters\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english', ngram_range=(1, 3))\n",
        "\n",
        "# Fit TF-IDF vectorizer on the texts and transform them into TF-IDF vectors\n",
        "tfidf_vector = tfidf_vectorizer.fit_transform(preprocessed_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the data"
      ],
      "metadata": {
        "id": "m4KeqnYJ7lv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler(with_mean=False)\n",
        "tfidf_vector_scaled = scaler.fit_transform(tfidf_vector)"
      ],
      "metadata": {
        "id": "gK12mXQI7jCc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data splitting"
      ],
      "metadata": {
        "id": "fo5gBgdU0G6z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1ukFjKgyPYML"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "x_train, x_test, labels_train, labels_test = train_test_split(tfidf_vector.toarray(), labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize models"
      ],
      "metadata": {
        "id": "qhiTvV-554Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=0, max_iter=1000),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=0),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=0),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "# Train each model\n",
        "for model_name, model in models.items():\n",
        "    model.fit(x_train, labels_train)\n",
        "    trained_models[model_name] = model"
      ],
      "metadata": {
        "id": "ZCK8ugJC50A4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train and evaluate a model"
      ],
      "metadata": {
        "id": "7EwJpbXr3ZOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate a model\n",
        "def evaluate_model(model, x_test, labels_test):\n",
        "    y_predicted = model.predict(x_test)\n",
        "\n",
        "    accuracy = accuracy_score(labels_test, y_predicted)\n",
        "    precision = precision_score(labels_test, y_predicted, average='weighted')\n",
        "    recall = recall_score(labels_test, y_predicted, average='weighted')\n",
        "    f1 = f1_score(labels_test, y_predicted, average='weighted')\n",
        "\n",
        "    classes = ['negative', 'neutral', 'positive']\n",
        "    class_metrics = {\n",
        "        'class': classes,\n",
        "        'precision': precision_score(labels_test, y_predicted, average=None, labels=classes),\n",
        "        'recall': recall_score(labels_test, y_predicted, average=None, labels=classes),\n",
        "        'f1': f1_score(labels_test, y_predicted, average=None, labels=classes)\n",
        "    }\n",
        "\n",
        "    print(f'\\nModel: {type(model).__name__}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    for cls, pre, rec, f1 in zip(class_metrics['class'], class_metrics['precision'], class_metrics['recall'], class_metrics['f1']):\n",
        "        print(f'{cls.capitalize()} class - Precision: {pre:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}')\n",
        "    print(f'Macro Average Precision: {precision:.4f}')\n",
        "    print(f'Macro Average Recall: {recall:.4f}')\n",
        "    print(f'Macro Average F1-Score: {f1:.4f}')\n",
        "\n",
        "    return {\n",
        "        'model': type(model).__name__,\n",
        "        'accuracy': accuracy,\n",
        "        'class_metrics': class_metrics\n",
        "    }"
      ],
      "metadata": {
        "id": "Vm1TTMvg3V4G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize models"
      ],
      "metadata": {
        "id": "RXPbJVOe3j71"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H2aRTOII3g6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate each model"
      ],
      "metadata": {
        "id": "kzrmWanD3pLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for model_name, model in trained_models.items():\n",
        "    result = evaluate_model(model, x_test, labels_test)\n",
        "    results.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPhbHuab3smo",
        "outputId": "dd033e76-5ce9-4b08-fd6e-014b4494da87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy: 0.6620\n",
            "Negative class - Precision: 0.6644, Recall: 0.3133, F1-Score: 0.4258\n",
            "Neutral class - Precision: 0.6447, Recall: 0.8159, F1-Score: 0.7203\n",
            "Positive class - Precision: 0.7004, Recall: 0.5887, F1-Score: 0.6397\n",
            "Macro Average Precision: 0.6666\n",
            "Macro Average Recall: 0.6620\n",
            "Macro Average F1-Score: 0.6397\n",
            "\n",
            "Model: MultinomialNB\n",
            "Accuracy: 0.6249\n",
            "Negative class - Precision: 0.6975, Recall: 0.1788, F1-Score: 0.2846\n",
            "Neutral class - Precision: 0.6067, Recall: 0.8312, F1-Score: 0.7014\n",
            "Positive class - Precision: 0.6621, Recall: 0.5172, F1-Score: 0.5807\n",
            "Macro Average Precision: 0.6394\n",
            "Macro Average Recall: 0.6249\n",
            "Macro Average F1-Score: 0.5807\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Accuracy: 0.6363\n",
            "Negative class - Precision: 0.6376, Recall: 0.2199, F1-Score: 0.3271\n",
            "Neutral class - Precision: 0.6195, Recall: 0.8379, F1-Score: 0.7123\n",
            "Positive class - Precision: 0.6803, Recall: 0.5222, F1-Score: 0.5909\n",
            "Macro Average Precision: 0.6429\n",
            "Macro Average Recall: 0.6363\n",
            "Macro Average F1-Score: 0.5909\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Accuracy: 0.5566\n",
            "Negative class - Precision: 0.3721, Recall: 0.3339, F1-Score: 0.3520\n",
            "Neutral class - Precision: 0.6058, Recall: 0.6309, F1-Score: 0.6181\n",
            "Positive class - Precision: 0.5545, Recall: 0.5458, F1-Score: 0.5501\n",
            "Macro Average Precision: 0.5526\n",
            "Macro Average Recall: 0.5566\n",
            "Macro Average F1-Score: 0.5501\n",
            "\n",
            "Model: KNeighborsClassifier\n",
            "Accuracy: 0.5299\n",
            "Negative class - Precision: 0.3784, Recall: 0.0222, F1-Score: 0.0419\n",
            "Neutral class - Precision: 0.5218, Recall: 0.9585, F1-Score: 0.6757\n",
            "Positive class - Precision: 0.6849, Recall: 0.1166, F1-Score: 0.1993\n",
            "Macro Average Precision: 0.5551\n",
            "Macro Average Recall: 0.5299\n",
            "Macro Average F1-Score: 0.1993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABK9tGXmG4XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Results to CSV"
      ],
      "metadata": {
        "id": "GmzcnfZM37Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('table_metrics.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Model', 'Class', 'Precision', 'Recall', 'F1-Score'])\n",
        "    for result in results:\n",
        "        for cls, pre, rec, f1 in zip(result['class_metrics']['class'], result['class_metrics']['precision'], result['class_metrics']['recall'], result['class_metrics']['f1']):\n",
        "            writer.writerow([result['model'], cls, pre, rec, f1])\n",
        "        writer.writerow([result['model'], 'Macro Average', result['accuracy'], '', ''])"
      ],
      "metadata": {
        "id": "m94fNH633399"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}